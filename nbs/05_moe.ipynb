{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture of Experts(MoE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp models.moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import math, torch, torch.nn.functional as F\n",
    "from torch import nn\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def binary(x, bits):\n",
    "    'converts integer vector into binary with number of `bits`'\n",
    "    mask = 2**torch.arange(bits, device=x.device, dtype=x.dtype)\n",
    "    return x.unsqueeze(-1).bitwise_and(mask).ne(0).byte()\n",
    "\n",
    "def lin(in_dim, out_dim, act=nn.ReLU, bias=True):\n",
    "    '''Linear layer followed by activation'''\n",
    "    if act is None: act = nn.Identity\n",
    "    return nn.Sequential(nn.Linear(in_dim, out_dim, bias), act())\n",
    "\n",
    "def mlp(in_dim, out_dim, hidden_dim=128, n_hidden=1, act=nn.ReLU, bias=True):\n",
    "    '''Multilayer perceptron with several hidden layers'''\n",
    "    if n_hidden==0: return lin(in_dim, out_dim, act, bias)\n",
    "    res = nn.Sequential(*lin(in_dim, hidden_dim, act, bias))\n",
    "    for _ in range(n_hidden-1): res+= lin(hidden_dim, hidden_dim, act, bias)\n",
    "    res += lin(hidden_dim, out_dim, None, bias)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# benchmark comparing nn.ModuleList and nn.Conv1d https://discuss.pytorch.org/t/parallel-execution-of-modules-in-nn-modulelist/43940/11\n",
    "class Experts(nn.ModuleList):\n",
    "    \"\"\"A class representing a collection of experts. Will compute weighted sum of results of topk experts depending on `selected_exps`\"\"\"\n",
    "    \n",
    "    def forward(self, x, routing_ws, selected_exps):\n",
    "        mask = F.one_hot(selected_exps, num_classes=len(self)).permute(2, 1, 0)\n",
    "        for i in range(len(self)):\n",
    "            idx, top_x = torch.where(mask[i])\n",
    "            if top_x.shape[0] == 0: continue\n",
    "            # in torch it is faster to index using lists than torch tensors\n",
    "            top_x_list = top_x.tolist()\n",
    "            res = self[i](x[top_x_list]) * routing_ws[top_x_list, idx.tolist(), None]\n",
    "            if 'out' not in locals(): out = torch.zeros((x.shape[0],*res.shape[1:]), device=x.device)\n",
    "            out.index_add_(0, top_x, res)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    '''Mixture of experts network'''\n",
    "    def __init__(self, in_dim, out_dim, n_experts=4, top_k=4, hidden_dim=128, act=nn.ReLU, save_probs=True):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "        self.gate = lin(in_dim, n_experts, act=None, bias=False)\n",
    "        self.experts = Experts(mlp(in_dim,out_dim, hidden_dim, act=act) for _ in range(n_experts))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        logits = self.gate(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        if self.save_probs: self.probs = probs\n",
    "        probs, selected_exps = torch.topk(probs, self.top_k, dim=-1)\n",
    "        probs /= probs.sum(dim=-1, keepdim=True)\n",
    "        return self.experts(x, probs, selected_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class FFF(MoE):\n",
    "    def __init__(self, in_dim, out_dim, depth=2, top_k=4, hidden_dim = 128, act=nn.ReLU, save_probs=True):\n",
    "        '''FFF which computes leaves probability distribution during forward'''\n",
    "        store_attr()\n",
    "        self.n_leaves = 2**depth\n",
    "        super().__init__(in_dim, out_dim, self.n_leaves, top_k, hidden_dim, act, save_probs)\n",
    "        # override gate to have size 1 less\n",
    "        self.gate = lin(in_dim, self.n_leaves-1, act=act, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        logits = self.gate(x)\n",
    "        logprobs = F.logsigmoid(torch.stack([-logits, logits],dim=2))     # (bs, n_leaves-1, 2)\n",
    "        probs = torch.zeros([bs,self.n_leaves], device=x.device)     # (bs, n_leaves)\n",
    "        for d in range(self.depth):\n",
    "            mask = logprobs[:, 2**d-1 : 2**(d+1)-1].view(bs,-1, 1)        # (bs, 2*2**d, 1)\n",
    "            probs = probs.view(bs, 2**(d+1), -1) + mask         # (bs, 2**(d+1), n_leaves//2**(d+1) )\n",
    "        probs = torch.exp(probs).view(bs, -1)\n",
    "        if self.save_probs: self.probs = probs.detach()\n",
    "        routing_weights, selected_exps = torch.topk(probs, self.top_k, dim=-1)\n",
    "        return self.experts(x, routing_weights, selected_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class InitFFF(MoE):\n",
    "    '''FFF which uses precomputed matrix for leaves distribution'''\n",
    "    def __init__(self, in_dim, out_dim, depth=2, top_k=4, hidden_dim = 128, act=nn.ReLU, save_probs=True):\n",
    "        self.n_leaves = 2**depth\n",
    "        super().__init__(in_dim, out_dim, self.n_leaves, top_k, hidden_dim, act, save_probs)\n",
    "        store_attr()\n",
    "        self.tree = self.init_tree_()\n",
    "        # override gate to have size 1 less\n",
    "        self.gate = lin(in_dim, self.n_leaves-1, act=act, bias=False)\n",
    "    \n",
    "    def init_tree_(self):\n",
    "        mask = binary(torch.arange(0,2**self.depth), self.depth).flip(-1)*2-1.\n",
    "        tree, res = torch.eye(self.n_leaves), []\n",
    "        for d in reversed(range(self.depth)): \n",
    "            tree = tree.view(self.n_leaves, -1, 2).sum(-1)\n",
    "            res.append(tree*mask[:,d][:,None])\n",
    "        return nn.Parameter(torch.cat(list(reversed(res)),dim=1), False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.gate(x)\n",
    "        # probs =  torch.exp(F.logsigmoid(logits[:,None]*self.tree).sum(-1))\n",
    "        probs =  F.softmax((logits[:,None]*self.tree).sum(-1), -1)\n",
    "        if self.save_probs: self.probs = probs.detach()\n",
    "        routing_weights, selected_exps = torch.topk(probs, self.top_k, dim=-1)\n",
    "        return self.experts(x, routing_weights, selected_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
